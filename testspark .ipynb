{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import org.apache.spark.SparkConf\nimport org.apache.spark.SparkContext\nimport org.apache.spark.SparkContext._\n"
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import org.apache.spark.rdd.RDD\n"
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "conf = org.apache.spark.SparkConf@5126867e\nsc = org.apache.spark.SparkContext@3d2973fe\n"
                    }, 
                    "metadata": {}
                }, 
                {
                    "execution_count": 3, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "org.apache.spark.SparkContext@3d2973fe"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "val conf: SparkConf = new SparkConf().setMaster(\"local[*]\").setAppName(\"ww\")\n\n  val sc: SparkContext = new SparkContext(conf)"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "l = List((-1,jhghj), (-1,lkjkl), (-2,jkhjkhk))\nrdd1 = ParallelCollectionRDD[0] at parallelize at <console>:42\n"
                    }, 
                    "metadata": {}
                }, 
                {
                    "execution_count": 4, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "ParallelCollectionRDD[0] at parallelize at <console>:42"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "val l = List((-1,\"jhghj\" ) , (-1 , \"lkjkl\") , (-2 ,\"jkhjkhk\") )\nval rdd1 = sc.parallelize(l) // rdd1[(Int, String)]"
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "k = List((-1,kl), (-1,kp), (-1,kt), (-2,lk))\nrdd2 = ParallelCollectionRDD[1] at parallelize at <console>:42\n"
                    }, 
                    "metadata": {}
                }, 
                {
                    "execution_count": 5, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "ParallelCollectionRDD[1] at parallelize at <console>:42"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "val k = List((-1,\"kl\" ) , (-1 , \"kp\") , (-1 ,\"kt\") , (-2 , \"lk\") )\nval rdd2 = sc.parallelize(k)"
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 6, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "Array((-2,(jkhjkhk,lk)), (-1,(jhghj,kl)), (-1,(jhghj,kp)), (-1,(jhghj,kt)), (-1,(lkjkl,kl)), (-1,(lkjkl,kp)), (-1,(lkjkl,kt)))"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "rdd1.join(rdd2).collect()"
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 7, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "Map(-1 -> lkjkl, -2 -> jkhjkhk)"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "rdd1.collectAsMap()\n"
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "(-1,(-2,lk))\n(-1,(-2,lu))\n(-1,(-2,lp))\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "u = List((-1,(-2,lk)), (-1,(-2,lu)), (-1,(-2,lp)))\nrdd3 = ParallelCollectionRDD[5] at parallelize at <console>:42\n"
                    }, 
                    "metadata": {}
                }, 
                {
                    "execution_count": 10, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "ParallelCollectionRDD[5] at parallelize at <console>:42"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "val u = List((-1,(-2 , \"lk\") ) , (-1 , (-2 , \"lu\")) , (-1 ,(-2 , \"lp\") ) )\nval rdd3 = sc.parallelize(u)\n\nrdd3.collect().foreach{println}\n//case(u,(p,k) =>  } "
        }, 
        {
            "execution_count": 29, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "-1 (-2,lk)\n-1 (-2,lu)\n-1 (-2,lp)\n"
                }
            ], 
            "source": "// l.foreach{ case(j,p) =>  println(j + \" \"    +  p) } "
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 12, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "Name: Compile Error\nMessage: <console>:44: error: not found: type rdd1\nError occurred in an application involving default arguments.\n       val rdd1 [List[Any]] = sc.parallelize(l)\n           ^\n\nStackTrace: "
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "\nval l = List( List(-1,\"jhghj\" ) , List(-1 , \"lkjkl\") , List(-2 ,\"jkhjkhk\") )\nval rdd1 : RDD[List[Any]] = sc.parallelize(l)\n\n// rdd1.collect().foreach(println)"
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/plain": "k = List(-1, ehdfh)\n"
                    }, 
                    "metadata": {}
                }, 
                {
                    "execution_count": 3, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "List(-1, ehdfh)"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "val k : List[Any]= List(-1,\"ehdfh\")\n"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Scala 2.11 with Spark", 
            "name": "scala", 
            "language": "scala"
        }, 
        "language_info": {
            "mimetype": "text/x-scala", 
            "version": "2.11.12", 
            "name": "scala", 
            "pygments_lexer": "scala", 
            "file_extension": ".scala", 
            "codemirror_mode": "text/x-scala"
        }
    }, 
    "nbformat": 4
}